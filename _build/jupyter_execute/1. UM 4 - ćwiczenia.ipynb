{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c26b5a",
   "metadata": {},
   "source": [
    "# Uczenie Maszynowe - ćwiczenia 4\n",
    "\n",
    "Celem dzisiejszych ćwiczeń jest rozpoczęcie pracy z scikit-learn i budowy pierwszych modeli regresyjnych (tak jak na wykładzie).\n",
    "\n",
    "## Zadanie 1 - zapoznanie z regresją\n",
    "\n",
    "Poniżej podano wektor dwóch zmiennych X (cechy) i y (zmienna celowa), które są od siebie zależne i mogą posłużyć do modelowania regresji. Zapoznajmy się najpierw z danymi:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16eb4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a711aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0,1,2,2.1,3,3.2,4]).reshape(-1,1)\n",
    "y = np.array([0,1.1,1.9,2.4,3.1,3.8,3.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33055c",
   "metadata": {},
   "source": [
    "1a. Wyświetl dane na wykresie punktowym używając biblioteki matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010725e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2749c14",
   "metadata": {},
   "source": [
    "Zależność jest linowa. Wpasujmy zatem prostą regresji w nasze dane.\n",
    "\n",
    "Proces uczenia modelu w scikit-learn wygląda podobnie dla wszystkich algorytmów. Należy kolejno:\n",
    "\n",
    "    Wczytać model: \n",
    "        from sklearn import linear_model\n",
    "    Zainstacjnować model\n",
    "        model = linear_model.LinearRegression()\n",
    "    Wytrenować: metodą fit(X,y)\n",
    "    Dokonać predykcji: metodą predict(X)\n",
    "    \n",
    "    1b. Zaimplementuj ten proces poniżej oraz\n",
    "    1c. Wyświetl równanie prostej\n",
    "    1d. Wyświetl dane i wpasowaną prostą regresji na wykresie\n",
    "    1f. Dokonaj predykcji dla zbioru czterech dowolnych wartości cechy X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a6593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fd4414a",
   "metadata": {},
   "source": [
    "## Zadanie 2 - proces modelowania regresji\n",
    "\n",
    "Proces budowy modelu zaczynamy od pozyskania danych. Skorzystamy z gotowych przykładów danych, które już dostępne są w bibliotece scikit-learn. Wczytaj dane dotyczące cen nieruchmości w Kalifornii jak poniżej i zapoznaj się ze zbiorem danych.\n",
    "Dokumentacja: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html\n",
    "\n",
    "Wczytany zostanie słownik, który ma następujące klucze 'data' - dane, 'target' - cel predykcji, 'target_names' - nazwa zmiennej celowej (zależnej), 'feature_names' - nazwy zmiennych.\n",
    "\n",
    "    2a. Wykorzystaj pandasa by uporządkować te dane w DataFrame\n",
    "    2b. Sprawdź czy danych są braki, puste wartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b45bd95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad577887",
   "metadata": {},
   "source": [
    "W celu przeprowadzenia treningu i skutecznej oceny modelu, dane należy podzielić na dwa (a w zasadzie na trzy) zbiory: treningowy i testowy (treningowy, walidacyjny i testowy).\n",
    "\n",
    "Zbiór treningowy służy do uczenia modelu, czyli dopasowania parametrów modelu do wzorców ukrytych w danych. Na podstawie zbioru treningowego model uczy się relacji między zmiennymi wejściowymi a wyjściową, którą chcemy przewidzieć.\n",
    "\n",
    "Zbiór testowy jest używany wyłącznie do oceny modelu, a więc do sprawdzenia, jak dobrze wyuczone zależności przekładają się na dane, których model wcześniej nie widział. Pomaga to ocenić, czy model jest ogólny i sprawdzi się na nowych, nieznanych danych.\n",
    "\n",
    "    2c.  Przeprwoadź podział danych na zbiór treningowy i testowy za pomocą funkcji train_test_split(). Zastosouj podział w stosunku 4:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf25fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23ab5c6e",
   "metadata": {},
   "source": [
    "Zanim zaczniemy proces modelowania, należy również dobrze zrozumieć dane. Dokonajmy więc najpierw odpowiedniej analizy naszych danych, musimy zwrócić uwagę przede wszystkim na\n",
    "\n",
    "    Jakie mamy dane - zrozumieć czym one są. Jakiego są typu - czy to wartości ciągłe czy kategoryczne?\n",
    "    Jakie mają wartości? Czy wykazują rozkład normalny?\n",
    "    Które cechy są najbardziej powiązane ze zmienną zależną?\n",
    "    Które cechy są ze sobą powiązane i potencjalne są redundantne?\n",
    "    \n",
    "Żeby szybko zrozumieć nasze dane, możemy szybko wykorzystać kilka przydantych funkcji:\n",
    "\n",
    "    Metoda .describe() w Pandas do opisu statystycznego danych\n",
    "    Biblioteka seaborn do wizualizacji rozkładów - seaborn.violinplot()\n",
    "    Wizualizacja zależności pomiędzy zmiennymi za pomocą scatterplot() lub seaborn.jointplot() (szybka wizualizacja seaborn.pairplot())\n",
    "    Korelacja między zmiennymi (metoda corr() pandasa i seaborn.heatmap() ) do wizualizacji\n",
    "\n",
    "Zapoznaj się z danymi:\n",
    "\n",
    "    2d. Zastanów się jakiego typu są zmienne w danych,\n",
    "    2e. Policz statystyki za pomocą metody describe()\n",
    "    2f. Zwizualizuj rozkłady danych (użyj violinplot)\n",
    "    2g. Zwizualizuj zależności między danymi.\n",
    "    2h. Policz korelacje między danymi. Policz korelację Spearmana i Pearsona. Jaka jest różnica? Użyj wizualizacji heatmap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c720dff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9187cbba",
   "metadata": {},
   "source": [
    "Kluczowy jest wybór odpowiednich cech do uczenia naszego modelu. Przystąpmy zatem do procesu uczenia. Użyjmy najpierw regresji liniowej.\n",
    "Proces uczenia jest prosty, tak jak w zadaniu 1 - instancjonujemy model, używamy metod fit() i predict() do odpowiednio - treningu i ewaluacji.\n",
    "Ewaluację przeprowadzamy z wykorzystaniem miar - jak na wykładzie. Miary dostępne są w ramach biblioteki scikit-learn (sklearn.metrics). Składania wygląda zwykle tak samo\n",
    "`nazwa_metody(prawdziwe_wyniki, predykowane_wyniki`\n",
    "\n",
    "    2i. Wybierz najbardziej powiązaną (wg. ciebie) cechę ze zmienną zależną i zbuduj dla niej model regresji liniowej. Dokonaj ewaluacji modelu za pomocą wybranej przez siebie miary. Sprawdź dokładnośc modelu na zbioru treningowym i testowym. Jakie widzisz różnice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d40c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd067cfc",
   "metadata": {},
   "source": [
    "## Zadanie 3. Regresja wieloraka\n",
    "\n",
    "Wykorzystanie tylko jednej zmiennej do predykcji naszej zmiennej zależnoej wydaje się bardzo ograniczone. Wykorzystajmy dlatego regresję wielomianową, gdzie predykcja odbywać się będzie z wykorzystaniem kilku zmiennych na raz.\n",
    "\n",
    "W sensie technicznym - nie musimy nic zmieniać. Użyjemy tego samego modelu, podając jako zmienną X więcej cech jednocześnie.\n",
    "\n",
    "    3. Powtórz proces treningu z zadania 2 z wykorzystaniem regresji wielorakiej. Spróbuj wybrać trzy różne kombinacje cech i sprawdź jak wpływają one na wynik końcowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c5682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ffcaf34",
   "metadata": {},
   "source": [
    "## Zadanie 4. Regresja wielomianowa\n",
    "\n",
    "Regresja liniowa to bardzo prosty model. Możemy zwiększyć zdolność naszego modelu do przedstawiania złożonych zależności między danymi wykorzystując kombinacje cech. Nazywa się to <b>inżynierią cech </b>.\n",
    "\n",
    "Dokonajmy kombinacji naszych cech by uzyskać bardziej złożone równanie regresji. Kombinacje oznaczają np. iloczyny lub ilorazy cech, ich kwadraty i tym podobne.\n",
    "\n",
    "Wykorzystać możemy do tego celu funkcję wbudowaną w scikit-learn, która obliczy kombinacje cech za nas. Jest to funkcja PolynomialFeatures z sklearn.preprocessing.\n",
    "\n",
    "    4. Powtórz proces treningu z zadania 3 z wykorzystaniem regresji wielomianowej. Spróbuj wybrać cztery różne kombinacje cech i sprawdź jak wpływają one na wynik końcowy.\n",
    "    4a. Policz kombinacje cech i oblicz ich korelacje oraz zwizualizuj związek ze zmienną celową.\n",
    "    4b. Wybierz najbardziej obiecujące cechy i wytrenuj model regresji wielomianowej (to nadal będzie model LinearRegression).\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc6d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "802de1f9",
   "metadata": {},
   "source": [
    "## Zadanie 5. Dobór odpowiedniego modelu\n",
    "\n",
    "Przeprowadźmy pewien eksperyment. Wykorzystaj kod z zadania 4 by obliczyć błąd predykcji na zbiorze testowym i treningowym dla różnych stopni wielomianiu i kombinacji cech. Zwizualizuj tę zależność.\n",
    "\n",
    "Możemy zaobserwować 3 przypadki:\n",
    "    \n",
    "    Dokładność na zbiorze treningowym i testowym jest niska\n",
    "    Dokładność na zbiorze treningowym jest wysoka a na testowym niska\n",
    "    Dokładność na obu zbiorach jest wysoka (średnia)\n",
    "    \n",
    "Co oznacza każdy z tych przypadków?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a0382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6540f060",
   "metadata": {},
   "source": [
    "## Zadanie 6. Regularyzacja modeli\n",
    "\n",
    "Regularyzacja to technika, która pomaga zapobiegać przeuczeniu (overfitting) modelu, narzucając dodatkowe wymogi do procesu treningu modelu. Najpopularniejszym przykładem będzie regularyzacjia regresji liniowej Ridge oraz Lasso. W Ridge i Lasso regresji regularyzacja jest wprowadzana przez dodatkowy człon w funkcji kosztu:\n",
    "\n",
    "    Ridge (L2): Dodaje kwadrat wartości współczynników do funkcji kosztu. Powoduje to, że współczynniki są „ściągane” bliżej zera, ale nigdy dokładnie do zera. Jest to przydatne, gdy chcemy zmniejszyć wagę mniej istotnych cech, ale ich nie usuwać.\n",
    "\n",
    "    Lasso (L1): Dodaje wartość absolutną współczynników do funkcji kosztu. Lasso może ustawiać współczynniki dokładnie na zero, co skutkuje selekcją cech. Jest przydatne, gdy chcemy automatycznie eliminować mniej istotne cechy.\n",
    "\n",
    "Dzięki regularyzacji model staje się bardziej ogólny i może lepiej działać na nowych danych.\n",
    "\n",
    "    6a. Wykorzystaj modele Ridge i Lasso (from sklearn.linear_model import Ridge, Lasso) by wytrenować regresję wielomianową dla naszego problemu. Zapoznaj się dokumentacją tych modeli. Przetestuj wyniki regresji z wykorzystaniem różnych parametrów dla tych modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46911f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba60c279",
   "metadata": {},
   "source": [
    "# Zadanie 7. Walidacja krzyżowa\n",
    "\n",
    "Podział danych na zbiór testowy i treningowy to uproszczony wariant, który ma pewną wadę - zbiór testowy *należy użyć tylko raz*. Dobór parametrów na podstawie wyników na zbiorze testowym jest obarczony błędem statystycznym.\n",
    "\n",
    "Dlatego też stosujemy walidację krzyżową.\n",
    "Walidacja krzyżowa to technika stosowana do oceny wydajności modelu na różnych podzbiorach danych. W klasycznej walidacji krzyżowej K-Fold dzielimy dane na K równych części (folds). Model jest trenowany na K-1 częściach, a pozostała część służy jako zbiór testowy. Proces jest powtarzany K razy, tak aby każdy fold pełnił rolę zbioru testowego raz. Wyniki są uśredniane, co daje bardziej stabilny i wiarygodny wynik niż pojedynczy podział na zbiory treningowy i testowy.\n",
    "\n",
    "Walidacja krzyżowa ma kilka zalet:\n",
    "\n",
    "    Stabilność i dokładność: Uśrednienie wyników z kilku foldów redukuje wpływ losowego podziału danych, co daje bardziej stabilny wynik.\n",
    "    Efektywność przy małych zbiorach danych: Pomaga maksymalnie wykorzystać dostępne dane do oceny modelu.\n",
    "    \n",
    "    7a. Wybierz najlepszy ze swoich modeli i dodaj do kodu walidację krzyżową wykorzystując jedną ze wbudowanych funkcji walidacji krzyżowej. Może być to cross_val_score lub klasa KFold (więcej omówimy na wykładzie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c5111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfcb87ff",
   "metadata": {},
   "source": [
    "# Zadanie 8*. Wykorzystaj algorytm SVR\n",
    "\n",
    "Wykorzystując napisany dotychczas kod, zaimplementuj algorytm SVR do predykcji tego problemu. Wykorzystując walidację krzyżową postaraj się dobrać jak najlepsze hiperparametry modelu. Dokonaj porównania wyników dla różnych hiperparametrów i \n",
    "wykorzystaj ich najlepszą kombinację do testu. Przykład działania algorytmu SVR znajdziesz w materiałach do wykładu.\n",
    "\n",
    "\n",
    "`* dodane ekstra przed ćwiczeniami - w razie gdyby zabrakło nam zadań`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee9e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
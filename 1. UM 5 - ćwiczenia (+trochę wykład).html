

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Uczenie Maszynowe - ćwiczenia 5 &#8212; Uczenie Maszynowe 2025</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '1. UM 5 - ćwiczenia (+trochę wykład)';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Uczenie Maszynowe - Wykład 4" href="1.%20UM%204.html" />
    <link rel="prev" title="Uczenie Maszynowe - ćwiczenia 4.5" href="1.%20UM%204.5%20-%20zadania%20dodatkowe.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="1.%20UM%201.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.jpg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.jpg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="1.%20UM%201.html">
                    Uczenie Maszynowe - Wykład 1
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.%20UM%201%20-%20%C4%87wiczenia.html">Uczenie Maszynowe - ćwiczenia 1</a></li>


<li class="toctree-l1"><a class="reference internal" href="1.%20UM%202%20-%20%C4%87wiczenia.html">Uczenie Maszynowe - ćwiczenia 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="1.%20UM%203%20-%20%C4%87wiczenia.html">Uczenie Maszynowe - ćwiczenia 3</a></li>
<li class="toctree-l1"><a class="reference internal" href="1.%20UM%202.html">Uczenie Maszynowe - Wykład 2</a></li>









<li class="toctree-l1"><a class="reference internal" href="1.%20UM%204%20-%20%C4%87wiczenia.html">Uczenie Maszynowe - ćwiczenia 4</a></li>

<li class="toctree-l1"><a class="reference internal" href="1.%20UM%203.html">Uczenie Maszynowe - Wykład 3</a></li>
<li class="toctree-l1"><a class="reference internal" href="1.%20UM%203%20-%20%C4%87wiczenia%20r.html">Uczenie Maszynowe - ćwiczenia 3 (plik roboczy)</a></li>
<li class="toctree-l1"><a class="reference internal" href="1.%20UM%204%20-%20%C4%87wiczenia%20r.html">Uczenie Maszynowe - ćwiczenia 4 (plik roboczy)</a></li>

<li class="toctree-l1"><a class="reference internal" href="1.%20UM%204.5%20-%20zadania%20dodatkowe.html">Uczenie Maszynowe - ćwiczenia 4.5</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Uczenie Maszynowe - ćwiczenia 5</a></li>





<li class="toctree-l1"><a class="reference internal" href="1.%20UM%204.html">Uczenie Maszynowe - Wykład 4</a></li>








</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F1. UM 5 - ćwiczenia (+trochę wykład).html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/1. UM 5 - ćwiczenia (+trochę wykład).ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Uczenie Maszynowe - ćwiczenia 5</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Uczenie Maszynowe - ćwiczenia 5</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#support-vector-regression-svr">Support Vector Regression (SVR)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zasada-epsilon-tube">Zasada Epsilon-Tube</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optymalizacja-i-marginesy">Optymalizacja i marginesy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kara-za-odchylenia-parametr-c">Kara za odchylenia - parametr C</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kernel-i-przestrzen-cech">Kernel i przestrzeń cech</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#epsilon-i-funkcja-kosztu">Epsilon i funkcja kosztu</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#zadanie-1">Zadanie 1.</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#zadanie-2">Zadanie 2.</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#regresja-k-nn-k-nearest-neighbors-regression"><strong>Regresja k-NN (k-Nearest Neighbors Regression)</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jak-dziala-algorytm-k-nn-w-regresji"><strong>Jak działa algorytm k-NN w regresji?</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametry-k-nn"><strong>Hiperparametry k-NN</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zalety-algorytmu-k-nn-w-regresji"><strong>Zalety algorytmu k-NN w regresji</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wady-algorytmu-k-nn-w-regresji"><strong>Wady algorytmu k-NN w regresji</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zadanie-3">Zadanie 3.</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#drzewa-decyzyjne">Drzewa decyzyjne</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#drzewo-decyzyjne">Drzewo decyzyjne</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regresja-z-wykorzystaniem-drzew-decyzyjnych">Regresja z wykorzystaniem drzew decyzyjnych</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#podzial-danych-proces-uczenia">Podział danych - proces uczenia</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predykcja">Predykcja</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#zalety">Zalety</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#wady">Wady</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kiedy-stosowac">Kiedy stosować</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zadanie-4">Zadanie 4.</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="uczenie-maszynowe-cwiczenia-5">
<h1>Uczenie Maszynowe - ćwiczenia 5<a class="headerlink" href="#uczenie-maszynowe-cwiczenia-5" title="Permalink to this heading">#</a></h1>
<p>Dziś poznamy nowe algorytmy uczenia maszynowego, dowiemy się czegoś o hiperparametrach modeli i zastosujemy je w praktyce!</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="support-vector-regression-svr">
<h1>Support Vector Regression (SVR)<a class="headerlink" href="#support-vector-regression-svr" title="Permalink to this heading">#</a></h1>
<p>Support Vector Regression (SVR) to algorytm oparty na zasadach Support Vector Machines (SVM), stosowany do regresji. Celem SVR jest znalezienie linii, krzywej lub powierzchni, która najlepiej odwzorowuje zależność między zmiennymi wejściowymi a wyjściową. Oto kluczowe aspekty działania SVR:</p>
<p>Wektory nośne (support vector) oznacza wykorzystanie punktów “najistotniejszych” do wpsowania modelu.</p>
<section id="zasada-epsilon-tube">
<h2>Zasada Epsilon-Tube<a class="headerlink" href="#zasada-epsilon-tube" title="Permalink to this heading">#</a></h2>
<p>SVR nie próbuje dokładnie dopasować modelu do każdego punktu danych. Zamiast tego, określa pewien margines błędu, zwany epsilon (ε), w którym model toleruje różnice między przewidywanymi a rzeczywistymi wartościami.</p>
<p>Jeśli punkt danych znajduje się w tym marginesie, jest traktowany jako “dobrze dopasowany” i nie wpływa na ostateczne rozwiązanie.
Punkty poza marginesem (leżące poza epsilon-tube) przyczyniają się do błędu i są karane w funkcji kosztu.</p>
</section>
<section id="optymalizacja-i-marginesy">
<h2>Optymalizacja i marginesy<a class="headerlink" href="#optymalizacja-i-marginesy" title="Permalink to this heading">#</a></h2>
<p>Celem SVR jest znalezienie takiej linii/krzywej/powierzchni, która:</p>
<p>Minimalizuje odchylenie od danych, jednocześnie dopuszczając tolerancję ε.
Maksymalizuje płaskość funkcji, co oznacza regularyzację.</p>
<p>Formuła optymalizacji w SVR uwzględnia dwa aspekty:</p>
<p>Minimalizację ∣∣w∣∣2 (ograniczanie modelu, aby był prosty).
Minimalizację błędów dla punktów poza epsilon-tube (punkty trudne do przewidzenia są karane proporcjonalnie do ich odległości od marginesu).</p>
</section>
<section id="kara-za-odchylenia-parametr-c">
<h2>Kara za odchylenia - parametr C<a class="headerlink" href="#kara-za-odchylenia-parametr-c" title="Permalink to this heading">#</a></h2>
<p>Parametr C kontroluje kompromis między dopasowaniem modelu a jego ogólną złożonością:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Niskie C: Model jest bardziej elastyczny, dopuszcza większe błędy, co może skutkować niedopasowaniem (underfitting).
Wysokie C: Model bardziej stara się dopasować do danych treningowych, co może prowadzić do przeuczenia (overfitting).
</pre></div>
</div>
</section>
<section id="kernel-i-przestrzen-cech">
<h2>Kernel i przestrzeń cech<a class="headerlink" href="#kernel-i-przestrzen-cech" title="Permalink to this heading">#</a></h2>
<p>SVR może pracować z danymi nieliniowymi dzięki tzw. trikom jądrowym (kernel tricks):</p>
<p>Kernel przekształca dane do wyższej przestrzeni wymiarów, gdzie można łatwiej znaleźć liniową hiperpowierzchnię (np. linię regresji).</p>
<p>Popularne kernele to:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    Linear (prosta regresja liniowa),
    Polynomial (model polinomiczny),
    RBF (nieliniowy model z funkcją radialną, dobry dla złożonych danych).
</pre></div>
</div>
</section>
<section id="epsilon-i-funkcja-kosztu">
<h2>Epsilon i funkcja kosztu<a class="headerlink" href="#epsilon-i-funkcja-kosztu" title="Permalink to this heading">#</a></h2>
<p>Parametr ε (epsilon) definiuje szerokość marginesu tolerancji:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Mniejsze epsilon: Model stara się bardziej dopasować do danych, co może skutkować przeuczeniem.
Większe epsilon: Model jest bardziej tolerancyjny na błędy i ignoruje drobne odchylenia.
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span>

<span class="c1"># Generate synthetic data</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="mi">5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">))</span>

<span class="c1"># Function to plot SVR with interactive controls</span>
<span class="k">def</span> <span class="nf">plot_svr</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">):</span>
    <span class="c1"># Train SVR model</span>
    <span class="n">svr</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">)</span>
    <span class="n">svr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="c1"># Generate predictions</span>
    <span class="n">X_fit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_fit</span> <span class="o">=</span> <span class="n">svr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_fit</span><span class="p">)</span>
    
    <span class="c1"># Plot data and SVR predictions</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data points&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_fit</span><span class="p">,</span> <span class="n">y_fit</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;SVR prediction&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">X_fit</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
        <span class="n">y_fit</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">,</span>
        <span class="n">y_fit</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Epsilon-tube (ε=</span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Support Vector Regression (Kernel: </span><span class="si">{</span><span class="n">kernel</span><span class="si">}</span><span class="s2">, C=</span><span class="si">{</span><span class="n">C</span><span class="si">}</span><span class="s2">, ε=</span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Create interactive widget</span>
<span class="n">interact</span><span class="p">(</span>
    <span class="n">plot_svr</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
    <span class="n">epsilon</span><span class="o">=</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span>
    <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "bef3ea24f0bf49228981ce1a60e862b0"}</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.plot_svr(C=1.0, epsilon=0.1, kernel=&#39;rbf&#39;)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span>

<span class="c1"># Generate synthetic data</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="mi">5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">))</span>

<span class="c1"># Function to plot SVR with interactive controls</span>
<span class="k">def</span> <span class="nf">plot_svr</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">):</span>
    <span class="c1"># Train SVR model</span>
    <span class="n">svr</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">)</span>
    <span class="n">svr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="c1"># Generate predictions</span>
    <span class="n">X_fit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_fit</span> <span class="o">=</span> <span class="n">svr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_fit</span><span class="p">)</span>
    
    <span class="c1"># Plot data and SVR predictions</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data points&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_fit</span><span class="p">,</span> <span class="n">y_fit</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;SVR prediction&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">X_fit</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
        <span class="n">y_fit</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">,</span>
        <span class="n">y_fit</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Epsilon-tube (ε=</span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Support Vector Regression (Kernel: </span><span class="si">{</span><span class="n">kernel</span><span class="si">}</span><span class="s2">, C=</span><span class="si">{</span><span class="n">C</span><span class="si">}</span><span class="s2">, ε=</span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Create interactive widget</span>
<span class="n">interact</span><span class="p">(</span>
    <span class="n">plot_svr</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
    <span class="n">epsilon</span><span class="o">=</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span>
    <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "c573eca0be634da199594065664edac6"}</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.plot_svr(C=1.0, epsilon=0.1, kernel=&#39;rbf&#39;)&gt;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="zadanie-1">
<h1>Zadanie 1.<a class="headerlink" href="#zadanie-1" title="Permalink to this heading">#</a></h1>
<p>Poniżej znajdziesz wygenerowane dwa zestawy danych. Wykorzystaj algorytm SVR by jak najlepiej rozwiązać problem predykcji. Wyświetl wpasowany model w dane by lepiej zwizualizować zależność parametrów od zachowania algorytmu.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">noise</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">dataset1_x</span> <span class="o">=</span> <span class="n">dataset1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">dataset1_y</span> <span class="o">=</span> <span class="n">dataset1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">dataset2</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">noise</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">dataset2_x</span> <span class="o">=</span> <span class="n">dataset2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">dataset2_y</span> <span class="o">=</span> <span class="n">dataset2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">dataset1_x</span><span class="p">,</span><span class="n">dataset1_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.PathCollection at 0x173b1b77280&gt;
</pre></div>
</div>
<img alt="_images/5d2f619606a2ab6998ad1568870e1a462e36db95c0d8ab2df096ec488ec4a7e1.png" src="_images/5d2f619606a2ab6998ad1568870e1a462e36db95c0d8ab2df096ec488ec4a7e1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">dataset2_x</span><span class="p">,</span><span class="n">dataset2_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.PathCollection at 0x173b13b3040&gt;
</pre></div>
</div>
<img alt="_images/a3e1ca9ae12388b1559dd79abea9e428f1634a319b3a69e3942fe9366667b475.png" src="_images/a3e1ca9ae12388b1559dd79abea9e428f1634a319b3a69e3942fe9366667b475.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="zadanie-2">
<h1>Zadanie 2.<a class="headerlink" href="#zadanie-2" title="Permalink to this heading">#</a></h1>
<p>Wykorzystując dane z poprzednich ćwiczeń (i podział na zbiory oraz sprawdzian kryżowy), wykorzystaj algorytm SVR do predykcji. Wesprzyj się dokumentacją: <a class="reference external" href="https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVR.html">https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVR.html</a></p>
<p>2a. Sprawdź wynik SVR (dla domyślnych parametrów, ale różnych typów kernela) dla różnych kombinacji cech. Potwierdź czy model działa najlepiej dla wcześniej wybranego zestawu cech czy też może zauważalna jest różnica.
2b. Dla wybranego zestawu cech, sprawdź różne kombinacje hiperparametrów modelu, w tym kernel, C, epsilon oraz gamma.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="regresja-k-nn-k-nearest-neighbors-regression">
<h1><strong>Regresja k-NN (k-Nearest Neighbors Regression)</strong><a class="headerlink" href="#regresja-k-nn-k-nearest-neighbors-regression" title="Permalink to this heading">#</a></h1>
<p>Regresja k-NN (ang. <em>k-Nearest Neighbors Regression</em>) to prosty, ale potężny algorytm uczenia maszynowego, który wykorzystuje odległości między punktami danych do przewidywania wartości ciągłych. Jest to metoda nieparametryczna, co oznacza, że nie zakłada konkretnej formy zależności między cechami a wartościami wyjściowymi.</p>
<hr class="docutils" />
<section id="jak-dziala-algorytm-k-nn-w-regresji">
<h2><strong>Jak działa algorytm k-NN w regresji?</strong><a class="headerlink" href="#jak-dziala-algorytm-k-nn-w-regresji" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Zbieranie danych treningowych</strong>:</p>
<ul class="simple">
<li><p>Algorytm zapamiętuje wszystkie dane treningowe i nie buduje żadnego modelu wstępnego.</p></li>
</ul>
</li>
<li><p><strong>Dla nowej próbki (punktu testowego)</strong>:</p>
<ul class="simple">
<li><p><strong>Krok 1</strong>: Oblicz odległości między nową próbką a wszystkimi punktami w zbiorze treningowym.</p>
<ul>
<li><p>Najczęściej używane metryki odległości to:</p>
<ul>
<li><p><strong>Odległość euklidesowa</strong>:
$<span class="math notranslate nohighlight">\(
d(x, x') = \sqrt{\sum_{i=1}^n (x_i - x'_i)^2}
\)</span>$</p></li>
<li><p><strong>Odległość Manhattan</strong>:
$<span class="math notranslate nohighlight">\(
d(x, x') = \sum_{i=1}^n |x_i - x'_i|
\)</span>$</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Krok 2</strong>: Wybierz ( k ) najbliższych sąsiadów (najmniejszych odległości) do punktu testowego.</p></li>
</ul>
</li>
<li><p><strong>Obliczanie wartości przewidywanej</strong>:</p>
<ul class="simple">
<li><p>Wartość przewidywana dla punktu testowego to <strong>średnia wartość wyjściowa ( y )</strong> najbliższych sąsiadów:
$<span class="math notranslate nohighlight">\(
\hat{y} = \frac{1}{k} \sum_{i=1}^k y_i
\)</span>$</p></li>
<li><p>Możliwe jest również stosowanie wag, gdzie bliżsi sąsiedzi mają większy wpływ na wynik:
$<span class="math notranslate nohighlight">\(
\hat{y} = \frac{\sum_{i=1}^k w_i \cdot y_i}{\sum_{i=1}^k w_i}
\)</span><span class="math notranslate nohighlight">\(
gdzie \)</span> w_i <span class="math notranslate nohighlight">\( to odwrotność odległości do sąsiada \)</span> w_i = \frac{1}{d(x, x’_i) + \epsilon} <span class="math notranslate nohighlight">\(, \)</span> \epsilon $ to mała wartość zapobiegająca dzieleniu przez zero.</p></li>
</ul>
</li>
<li><p><strong>Powtórzenie dla wszystkich punktów testowych</strong>:</p>
<ul class="simple">
<li><p>Algorytm wykonuje powyższe kroki dla każdej próbki w zbiorze testowym.</p></li>
</ul>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="hiperparametry-k-nn">
<h2><strong>Hiperparametry k-NN</strong><a class="headerlink" href="#hiperparametry-k-nn" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Liczba sąsiadów <span class="math notranslate nohighlight">\(k\)</span></strong>:</p>
<ul class="simple">
<li><p>Małe <span class="math notranslate nohighlight">\( k \)</span>:</p>
<ul>
<li><p>Model bardziej wrażliwy na szum w danych (przejawia tendencję do overfittingu).</p></li>
</ul>
</li>
<li><p>Duże <span class="math notranslate nohighlight">\( k \)</span>:</p>
<ul>
<li><p>Model uśrednia wartości w szerszym zakresie, co może prowadzić do underfittingu.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Metryka odległości</strong>:</p>
<ul class="simple">
<li><p>Najczęściej używana jest odległość euklidesowa, ale można stosować inne miary, takie jak Manhattan, Minkowski czy metryki specjalistyczne.</p></li>
</ul>
</li>
<li><p><strong>Wagi sąsiadów</strong>:</p>
<ul class="simple">
<li><p>Domyślnie wszyscy sąsiedzi mają równą wagę.</p></li>
<li><p>Można stosować wagi zależne od odległości, aby bliżsi sąsiedzi mieli większy wpływ.</p></li>
</ul>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="zalety-algorytmu-k-nn-w-regresji">
<h2><strong>Zalety algorytmu k-NN w regresji</strong><a class="headerlink" href="#zalety-algorytmu-k-nn-w-regresji" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Prostota</strong>:</p>
<ul class="simple">
<li><p>Algorytm jest łatwy do zrozumienia i implementacji.</p></li>
</ul>
</li>
<li><p><strong>Elastyczność</strong>:</p>
<ul class="simple">
<li><p>Działa dobrze z danymi o skomplikowanych i nieliniowych zależnościach.</p></li>
</ul>
</li>
<li><p><strong>Brak założeń</strong>:</p>
<ul class="simple">
<li><p>Nie wymaga wstępnych założeń o rozkładzie danych.</p></li>
</ul>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="wady-algorytmu-k-nn-w-regresji">
<h2><strong>Wady algorytmu k-NN w regresji</strong><a class="headerlink" href="#wady-algorytmu-k-nn-w-regresji" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Koszt obliczeniowy</strong>:</p>
<ul class="simple">
<li><p>Algorytm wymaga obliczania odległości dla wszystkich punktów w zbiorze treningowym dla każdej próbki testowej, co może być kosztowne dla dużych zbiorów danych.</p></li>
</ul>
</li>
<li><p><strong>Wrażliwość na dane</strong>:</p>
<ul class="simple">
<li><p>Wrażliwość na szum i wartości odstające, szczególnie dla małych wartości <span class="math notranslate nohighlight">\( k \)</span>.</p></li>
</ul>
</li>
<li><p><strong>Problemy ze skalą danych</strong>:</p>
<ul class="simple">
<li><p>Algorytm jest wrażliwy na różnice w skali cech, dlatego standaryzacja lub normalizacja danych jest zwykle konieczna.</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span>

<span class="c1"># Generate synthetic dataset</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">160</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">160</span><span class="p">:]</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="mi">160</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">160</span><span class="p">:]</span>

<span class="c1"># Interactive function for k-NN</span>
<span class="k">def</span> <span class="nf">interactive_knn</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">):</span>
    <span class="c1"># Train k-NN regressor</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Predict on test set</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    
    <span class="c1"># Calculate MSE</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    
    <span class="c1"># Plot training data, test data, and predictions</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="c1"># Scatter plot of training and test data</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training Data&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test Data&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    
    <span class="c1"># Line plot of predictions</span>
    <span class="n">X_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">500</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_pred_range</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_range</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_range</span><span class="p">,</span> <span class="n">y_pred_range</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;k-NN Predictions&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="c1"># Titles and labels</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;k-NN Regression (k=</span><span class="si">{</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">, weights=&#39;</span><span class="si">{</span><span class="n">weights</span><span class="si">}</span><span class="s2">&#39;)</span><span class="se">\n</span><span class="s2">MSE: </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Target&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Interactive widgets for k and weights</span>
<span class="n">interact</span><span class="p">(</span>
    <span class="n">interactive_knn</span><span class="p">,</span>
    <span class="n">n_neighbors</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">&#39;k (Neighbors)&#39;</span><span class="p">),</span>
    <span class="n">weights</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">RadioButtons</span><span class="p">(</span>
        <span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">],</span>
        <span class="n">value</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Weights:&#39;</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "2ff37d09208c41868497abcc71f23873"}</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.interactive_knn(n_neighbors=3, weights=&#39;uniform&#39;)&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="zadanie-3">
<h2>Zadanie 3.<a class="headerlink" href="#zadanie-3" title="Permalink to this heading">#</a></h2>
<p>Wykorzystując dane z poprzednich ćwiczeń (i podział na zbiory oraz sprawdzian kryżowy), wykorzystaj algorytm k-NN do predykcji. Wesprzyj się dokumentacją: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html</a></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>3a. Sprawdź wynik k-NN dla wybranego przez Ciebie zestawu parametrów.
3b. Dla wybranego zestawu cech, sprawdź różne kombinacje hiperparametrów i wykonaj krzywe złożoności dla parametry n_neighbors oraz p.
</pre></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="drzewa-decyzyjne">
<h1>Drzewa decyzyjne<a class="headerlink" href="#drzewa-decyzyjne" title="Permalink to this heading">#</a></h1>
<p>Drzewa decyzyjne to popularny algorytm uczenia maszynowego, który można wykorzystać zarówno do zadań klasyfikacji, jak i regresji. W przypadku regresji drzewa decyzyjne służą do przewidywania wartości ciągłych, co czyni je potężnym narzędziem w modelowaniu danych z nieliniowymi i złożonymi zależnościami.</p>
<section id="drzewo-decyzyjne">
<h2>Drzewo decyzyjne<a class="headerlink" href="#drzewo-decyzyjne" title="Permalink to this heading">#</a></h2>
<p>Drzewo decyzyjne to struktura przypominająca diagram, w której dane są dzielone na podstawie warunków logicznych, tworząc węzły i gałęzie.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Korzeń drzewa: Punkt początkowy, zawierający całe dane wejściowe.

Węzły decyzyjne: Punkty, w których dane są dzielone na podstawie określonego warunku (np. cechy, która najlepiej wyjaśnia dane w danym momencie).

Liście: Końcowe węzły, które reprezentują przewidywaną wartość w przypadku regresji.
</pre></div>
</div>
</section>
<section id="regresja-z-wykorzystaniem-drzew-decyzyjnych">
<h2>Regresja z wykorzystaniem drzew decyzyjnych<a class="headerlink" href="#regresja-z-wykorzystaniem-drzew-decyzyjnych" title="Permalink to this heading">#</a></h2>
<section id="podzial-danych-proces-uczenia">
<h3>Podział danych - proces uczenia<a class="headerlink" href="#podzial-danych-proces-uczenia" title="Permalink to this heading">#</a></h3>
<p>Drzewo iteracyjnie dzieli dane wejściowe na podzbiory na podstawie wybranej cechy i warunku, który minimalizuje błąd predykcji.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Na przykład powierzchnia mieszkania &gt; 50m2 -&gt; tak lub nie, dzieli dane na dwa podzbiory w których predykcja ma konkretną wartość.
</pre></div>
</div>
<p>Używa się miar takich jak średni błąd kwadratowy (MSE) lub średni absolutny błąd (MAE), aby określić najlepszy podział.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Kryterium podziału to róznica między rzeczywistą wartością a średnią wartością w podgrupie, która powstała.
</pre></div>
</div>
<p>Algorytm kontynuuje podziały, aż osiągnie określone kryterium stopu, np. minimalną liczbę próbek w liściu, maksymalną głębokość drzewa lub brak dalszej poprawy błędu.</p>
</section>
<section id="predykcja">
<h3>Predykcja<a class="headerlink" href="#predykcja" title="Permalink to this heading">#</a></h3>
<p>Wartość przewidywana w liściu drzewa decyzyjnego to średnia wartość wyników w danym podzbiorze danych.</p>
</section>
<section id="zalety">
<h3>Zalety<a class="headerlink" href="#zalety" title="Permalink to this heading">#</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Drzewa są bardzo proste w użyciu i intuicyjne
Są zdolne do obsługi wysoce nieliniowych związków
Nie ma potrzeby skalowania danych
</pre></div>
</div>
</section>
<section id="wady">
<h3>Wady<a class="headerlink" href="#wady" title="Permalink to this heading">#</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Drzewa są podatne na overfitting
Ich przewidywania są średnimi, a zatem są skokowe
</pre></div>
</div>
</section>
<section id="kiedy-stosowac">
<h3>Kiedy stosować<a class="headerlink" href="#kiedy-stosowac" title="Permalink to this heading">#</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Gdy dane są wysoce nielinowe
Gdy interpretowalność modelu jest kluczowa
W danych występują złożone interakcje między cechami, a które trudno ująć np. regresją wielomianową
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import additional library for tree visualization</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">plot_tree</span>

<span class="c1"># Adjust interactive function to include tree visualization</span>
<span class="k">def</span> <span class="nf">interactive_tree_with_plot</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Train the Decision Tree Regressor with selected hyperparameters</span>
    <span class="n">regressor</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span>
        <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span> 
        <span class="n">min_samples_split</span><span class="o">=</span><span class="n">min_samples_split</span><span class="p">,</span> 
        <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">min_samples_leaf</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>
    <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Predict on the training and test set</span>
    <span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    
    <span class="c1"># Calculate Mean Squared Error</span>
    <span class="n">train_mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)</span>
    <span class="n">test_mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
    
    <span class="c1"># Create subplots for predictions and tree structure</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    
    <span class="c1"># Plot the data and the regression tree predictions</span>
    <span class="n">X_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">500</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_pred_range</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_range</span><span class="p">)</span>
    
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Data&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test Data&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_range</span><span class="p">,</span> <span class="n">y_pred_range</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Tree Prediction&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Decision Tree Regressor</span><span class="se">\n</span><span class="s2">Train MSE: </span><span class="si">{</span><span class="n">train_mse</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, Test MSE: </span><span class="si">{</span><span class="n">test_mse</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Target&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Visualize the decision tree structure</span>
    <span class="n">plot_tree</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Feature&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Decision Tree Structure&quot;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Interactive widgets for hyperparameters</span>
<span class="n">interact</span><span class="p">(</span>
    <span class="n">interactive_tree_with_plot</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Max Depth&#39;</span><span class="p">),</span>
    <span class="n">min_samples_split</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Min Samples Split&#39;</span><span class="p">),</span>
    <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Min Samples Leaf&#39;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "b72545038ea547b9b50f81165316f6e0"}</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.interactive_tree_with_plot(max_depth=3, min_samples_split=2, min_samples_leaf=1)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate a more non-linear dataset</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_nl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Random values between 0 and 10</span>
<span class="n">y_nl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X_nl</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">X_nl</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Sinusoidal with noise</span>

<span class="c1"># Split into training and testing sets</span>
<span class="n">X_train_nl</span><span class="p">,</span> <span class="n">X_test_nl</span><span class="p">,</span> <span class="n">y_train_nl</span><span class="p">,</span> <span class="n">y_test_nl</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_nl</span><span class="p">,</span> <span class="n">y_nl</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Interactive function for non-linear example</span>
<span class="k">def</span> <span class="nf">interactive_tree_with_plot_nonlinear</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Train the Decision Tree Regressor with selected hyperparameters</span>
    <span class="n">regressor</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span>
        <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span> 
        <span class="n">min_samples_split</span><span class="o">=</span><span class="n">min_samples_split</span><span class="p">,</span> 
        <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">min_samples_leaf</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>
    <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_nl</span><span class="p">,</span> <span class="n">y_train_nl</span><span class="p">)</span>
    
    <span class="c1"># Predict on the training and test set</span>
    <span class="n">y_pred_train_nl</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_nl</span><span class="p">)</span>
    <span class="n">y_pred_test_nl</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_nl</span><span class="p">)</span>
    
    <span class="c1"># Calculate Mean Squared Error</span>
    <span class="n">train_mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train_nl</span><span class="p">,</span> <span class="n">y_pred_train_nl</span><span class="p">)</span>
    <span class="n">test_mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test_nl</span><span class="p">,</span> <span class="n">y_pred_test_nl</span><span class="p">)</span>
    
    <span class="c1"># Create subplots for predictions and tree structure</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>
    
    <span class="c1"># Plot the data and the regression tree predictions</span>
    <span class="n">X_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">X_nl</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X_nl</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">500</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_pred_range</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_range</span><span class="p">)</span>
    
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_nl</span><span class="p">,</span> <span class="n">y_train_nl</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Data&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test_nl</span><span class="p">,</span> <span class="n">y_test_nl</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test Data&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_range</span><span class="p">,</span> <span class="n">y_pred_range</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Tree Prediction&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Decision Tree Regressor (Non-Linear Example)</span><span class="se">\n</span><span class="s2">Train MSE: </span><span class="si">{</span><span class="n">train_mse</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, Test MSE: </span><span class="si">{</span><span class="n">test_mse</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Target&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Visualize the decision tree structure</span>
    <span class="n">plot_tree</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Feature&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Decision Tree Structure&quot;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Interactive widgets for hyperparameters</span>
<span class="n">interact</span><span class="p">(</span>
    <span class="n">interactive_tree_with_plot_nonlinear</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Max Depth&#39;</span><span class="p">),</span>
    <span class="n">min_samples_split</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Min Samples Split&#39;</span><span class="p">),</span>
    <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Min Samples Leaf&#39;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">Input In [8],</span> in <span class="ni">&lt;cell line: 7&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">y_nl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X_nl</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">X_nl</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Sinusoidal with noise</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="c1"># Split into training and testing sets</span>
<span class="ne">----&gt; </span><span class="mi">7</span> <span class="n">X_train_nl</span><span class="p">,</span> <span class="n">X_test_nl</span><span class="p">,</span> <span class="n">y_train_nl</span><span class="p">,</span> <span class="n">y_test_nl</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_nl</span><span class="p">,</span> <span class="n">y_nl</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="c1"># Interactive function for non-linear example</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="k">def</span> <span class="nf">interactive_tree_with_plot_nonlinear</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>     <span class="c1"># Train the Decision Tree Regressor with selected hyperparameters</span>

<span class="ne">NameError</span>: name &#39;train_test_split&#39; is not defined
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="zadanie-4">
<h2>Zadanie 4.<a class="headerlink" href="#zadanie-4" title="Permalink to this heading">#</a></h2>
<p>Wykorzystując dane z poprzednich ćwiczeń (i podział na zbiory oraz sprawdzian kryżowy), wykorzystaj algorytm k-NN do predykcji. Wesprzyj się dokumentacją: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html</a></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>4a. Wytrenuj model dla danych dobierając parametry na podstawie krzywych złożoności.
4b. Dla wybranego modelu zwizualizuj drzewo i dokonaj jego interpretacji.
4c. Przeanalizuj predykcje, w których przewidywana wartość znacząco odstaje od predykcji drzewa. Spróbuj zinterpretować przyczynę tego zdarzenia.
</pre></div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="1.%20UM%204.5%20-%20zadania%20dodatkowe.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Uczenie Maszynowe - ćwiczenia 4.5</p>
      </div>
    </a>
    <a class="right-next"
       href="1.%20UM%204.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Uczenie Maszynowe - Wykład 4</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Uczenie Maszynowe - ćwiczenia 5</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#support-vector-regression-svr">Support Vector Regression (SVR)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zasada-epsilon-tube">Zasada Epsilon-Tube</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optymalizacja-i-marginesy">Optymalizacja i marginesy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kara-za-odchylenia-parametr-c">Kara za odchylenia - parametr C</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kernel-i-przestrzen-cech">Kernel i przestrzeń cech</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#epsilon-i-funkcja-kosztu">Epsilon i funkcja kosztu</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#zadanie-1">Zadanie 1.</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#zadanie-2">Zadanie 2.</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#regresja-k-nn-k-nearest-neighbors-regression"><strong>Regresja k-NN (k-Nearest Neighbors Regression)</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jak-dziala-algorytm-k-nn-w-regresji"><strong>Jak działa algorytm k-NN w regresji?</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametry-k-nn"><strong>Hiperparametry k-NN</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zalety-algorytmu-k-nn-w-regresji"><strong>Zalety algorytmu k-NN w regresji</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wady-algorytmu-k-nn-w-regresji"><strong>Wady algorytmu k-NN w regresji</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zadanie-3">Zadanie 3.</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#drzewa-decyzyjne">Drzewa decyzyjne</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#drzewo-decyzyjne">Drzewo decyzyjne</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regresja-z-wykorzystaniem-drzew-decyzyjnych">Regresja z wykorzystaniem drzew decyzyjnych</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#podzial-danych-proces-uczenia">Podział danych - proces uczenia</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predykcja">Predykcja</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#zalety">Zalety</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#wady">Wady</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kiedy-stosowac">Kiedy stosować</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zadanie-4">Zadanie 4.</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Kamil Smolak
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>